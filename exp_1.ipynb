{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  1 21:08:55 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 529.04       Driver Version: 529.04       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   44C    P5     7W /  94W |    588MiB /  8188MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2036    C+G   ...8wekyb3d8bbwe\\msteams.exe    N/A      |\n",
      "|    0   N/A  N/A      4108    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      9232    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     10956    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     12216    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     12648    C+G   ...v1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A     13136    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13160    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15492    C+G   ...mmandCenterBackground.exe    N/A      |\n",
      "|    0   N/A  N/A     16024    C+G   ...ightStudio-background.exe    N/A      |\n",
      "|    0   N/A  N/A     18200    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     18572    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     19108    C+G   ...ystemEventUtilityHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19428    C+G   ...v10z8vjag6ke6\\HP.myHP.exe    N/A      |\n",
      "|    0   N/A  N/A     21952    C+G   ...151.72\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     23432    C+G   ...(x86)\\AdGuard\\Adguard.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Cheak gpu\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train/train/train.csv\")\n",
    "test = pd.read_csv(\"test/test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      image_id  filename  label\n",
      "0            1     1.jpg      2\n",
      "1            2     2.jpg      4\n",
      "2            3     3.jpg      2\n",
      "3            4     4.jpg      3\n",
      "4            5     5.jpg      5\n",
      "...        ...       ...    ...\n",
      "7195      7196  7196.jpg      4\n",
      "7196      7197  7197.jpg      4\n",
      "7197      7198  7198.jpg      4\n",
      "7198      7199  7199.jpg      2\n",
      "7199      7200  7200.jpg      2\n",
      "\n",
      "[7200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      image_id   filename\n",
      "0         7201   7201.jpg\n",
      "1         7202   7202.jpg\n",
      "2         7203   7203.jpg\n",
      "3         7204   7204.jpg\n",
      "4         7205   7205.jpg\n",
      "...        ...        ...\n",
      "4795     11996  11996.jpg\n",
      "4796     11997  11997.jpg\n",
      "4797     11998  11998.jpg\n",
      "4798     11999  11999.jpg\n",
      "4799     12000  12000.jpg\n",
      "\n",
      "[4800 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"train/train/images\"\n",
    "test_folder = \"test/test/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data generator\n",
    "train_gen = ImageDataGenerator(\n",
    "rotation_range=45,\n",
    "rescale=1./255,\n",
    "horizontal_flip=True\n",
    ")\n",
    "test_gen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'filename' \n",
    "label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have your original training data in 'train_data'\n",
    "# train_data, val_data = train_test_split(train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7200 validated image filenames.\n",
      "Found 4800 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_gen.flow_from_dataframe( dataframe = train, \n",
    "                                            directory = train_folder, x_col = filename, \n",
    "                                            y_col = label, seed = 42,\n",
    "                                            batch_size = 32, shuffle = True, \n",
    "                                            class_mode=\"raw\",target_size = (224, 224))\n",
    "\n",
    "# val_data = train_gen.flow_from_dataframe(\n",
    "#                                                 dataframe=val_data,\n",
    "#                                                 directory=train_folder,  # Assuming validation data is in the same folder as training data\n",
    "#                                                 x_col=filename,\n",
    "#                                                 y_col=label,\n",
    "#                                                 seed=42,\n",
    "#                                                 batch_size=32,\n",
    "#                                                 shuffle=False,\n",
    "#                                                 class_mode=\"sparse\",\n",
    "#                                                 target_size=(224, 224)\n",
    "# )\n",
    "\n",
    "test_data = test_gen.flow_from_dataframe(   dataframe = test, \n",
    "                                            directory = test_folder, x_col = filename, \n",
    "                                            y_col = None,\n",
    "                                            batch_size = 32, shuffle = False, \n",
    "                                            class_mode=None,target_size = (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.preprocessing.image.DataFrameIterator at 0x1da63b89c10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming train_data is your DataFrameIterator\n",
    "batch = next(train_data)\n",
    "\n",
    "# Extract data and labels from the batch\n",
    "images, labels = batch\n",
    "\n",
    "labels = labels.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.9239305 , 0.26902854, 0.4886364 ],\n",
       "          [0.9272554 , 0.27235332, 0.49196118],\n",
       "          [0.93058014, 0.27567816, 0.49528602],\n",
       "          ...,\n",
       "          [0.9948733 , 0.85296446, 0.8021672 ],\n",
       "          [0.8940659 , 0.7380827 , 0.6897926 ],\n",
       "          [0.97647065, 0.8356729 , 0.761838  ]],\n",
       " \n",
       "         [[0.9740081 , 0.319106  , 0.53871393],\n",
       "          [0.9706832 , 0.31578124, 0.53538907],\n",
       "          [0.9673584 , 0.3124564 , 0.53206426],\n",
       "          ...,\n",
       "          [0.9882237 , 0.84536487, 0.79480505],\n",
       "          [0.8992907 , 0.74449486, 0.6945423 ],\n",
       "          [0.97647065, 0.8306858 , 0.7578007 ]],\n",
       " \n",
       "         [[0.9203936 , 0.2654916 , 0.48509946],\n",
       "          [0.92395586, 0.2690539 , 0.48866177],\n",
       "          [0.9275182 , 0.27261618, 0.49222404],\n",
       "          ...,\n",
       "          [0.981574  , 0.83776534, 0.787443  ],\n",
       "          [0.9045153 , 0.75090694, 0.699292  ],\n",
       "          [0.97647065, 0.82569855, 0.7537634 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.6569521 , 0.6569521 , 0.6569521 ],\n",
       "          [0.6234968 , 0.6234968 , 0.6234968 ],\n",
       "          [0.69727373, 0.69727373, 0.69727373],\n",
       "          ...,\n",
       "          [0.62992215, 0.62992215, 0.62992215],\n",
       "          [0.6375217 , 0.6375217 , 0.6375217 ],\n",
       "          [0.6451213 , 0.6451213 , 0.6451213 ]],\n",
       " \n",
       "         [[0.65908945, 0.65908945, 0.65908945],\n",
       "          [0.62064695, 0.62064695, 0.62064695],\n",
       "          [0.7032109 , 0.7032109 , 0.7032109 ],\n",
       "          ...,\n",
       "          [0.5326498 , 0.5326498 , 0.5326498 ],\n",
       "          [0.53003746, 0.53003746, 0.53003746],\n",
       "          [0.52742517, 0.52742517, 0.52742517]],\n",
       " \n",
       "         [[0.6612268 , 0.6612268 , 0.6612268 ],\n",
       "          [0.61779714, 0.61779714, 0.61779714],\n",
       "          [0.70914805, 0.70914805, 0.70914805],\n",
       "          ...,\n",
       "          [0.56605273, 0.56605273, 0.56605273],\n",
       "          [0.5670028 , 0.5670028 , 0.5670028 ],\n",
       "          [0.5679527 , 0.5679527 , 0.5679527 ]]],\n",
       " \n",
       " \n",
       "        [[[0.58548796, 0.67612433, 0.73901623],\n",
       "          [0.59209037, 0.68520266, 0.74891984],\n",
       "          [0.59869283, 0.69428104, 0.7588235 ],\n",
       "          ...,\n",
       "          [0.08649206, 0.08257049, 0.07472736],\n",
       "          [0.17365539, 0.16903003, 0.16095227],\n",
       "          [0.13131982, 0.11563355, 0.10386885]],\n",
       " \n",
       "         [[0.59906167, 0.6855707 , 0.7409419 ],\n",
       "          [0.5957604 , 0.68309486, 0.7401166 ],\n",
       "          [0.5924592 , 0.68061894, 0.7392913 ],\n",
       "          ...,\n",
       "          [0.10712465, 0.10320308, 0.09535994],\n",
       "          [0.16375175, 0.15665048, 0.14774743],\n",
       "          [0.14204878, 0.1263625 , 0.11459779]],\n",
       " \n",
       "         [[0.6575863 , 0.7330634 , 0.78796536],\n",
       "          [0.64438146, 0.72233444, 0.7772364 ],\n",
       "          [0.6311766 , 0.7116055 , 0.7665075 ],\n",
       "          ...,\n",
       "          [0.12775722, 0.12383567, 0.11599252],\n",
       "          [0.15384811, 0.14427091, 0.13454258],\n",
       "          [0.15277772, 0.13709144, 0.12532674]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.42042497, 0.42434654, 0.392974  ],\n",
       "          [0.4102532 , 0.41417477, 0.3828022 ],\n",
       "          [0.3920344 , 0.39985302, 0.36653194],\n",
       "          ...,\n",
       "          [0.19415441, 0.21178922, 0.22550246],\n",
       "          [0.1916785 , 0.2101386 , 0.22467716],\n",
       "          [0.18920259, 0.208488  , 0.22385184]],\n",
       " \n",
       "         [[0.43445513, 0.4383767 , 0.40700415],\n",
       "          [0.39374712, 0.3976687 , 0.36629614],\n",
       "          [0.40028742, 0.40975666, 0.3756103 ],\n",
       "          ...,\n",
       "          [0.23016332, 0.2458496 , 0.2576143 ],\n",
       "          [0.21695848, 0.23264475, 0.24440946],\n",
       "          [0.20375364, 0.21943991, 0.23120461]],\n",
       " \n",
       "         [[0.44848529, 0.45240685, 0.4210343 ],\n",
       "          [0.37724105, 0.38116264, 0.34979007],\n",
       "          [0.40854046, 0.41966033, 0.38468862],\n",
       "          ...,\n",
       "          [0.2375818 , 0.25326806, 0.26503277],\n",
       "          [0.24913605, 0.2648223 , 0.276587  ],\n",
       "          [0.2606903 , 0.27637658, 0.28814128]]],\n",
       " \n",
       " \n",
       "        [[[0.16444087, 0.16444087, 0.172284  ],\n",
       "          [0.15700062, 0.15700062, 0.16484375],\n",
       "          [0.14225802, 0.14225802, 0.15010116],\n",
       "          ...,\n",
       "          [0.83542377, 0.83542377, 0.83542377],\n",
       "          [0.8483331 , 0.8483331 , 0.8483331 ],\n",
       "          [0.81443155, 0.81443155, 0.8172226 ]],\n",
       " \n",
       "         [[0.17026968, 0.17026968, 0.17811282],\n",
       "          [0.16611385, 0.16611385, 0.17395699],\n",
       "          [0.15867363, 0.15867363, 0.16651677],\n",
       "          ...,\n",
       "          [0.8461025 , 0.8461025 , 0.8461025 ],\n",
       "          [0.83060384, 0.83060384, 0.8322796 ],\n",
       "          [0.74250925, 0.74250925, 0.7502605 ]],\n",
       " \n",
       "         [[0.17406581, 0.17406581, 0.18190895],\n",
       "          [0.17082734, 0.17082734, 0.17867048],\n",
       "          [0.16778687, 0.16778687, 0.17563   ],\n",
       "          ...,\n",
       "          [0.8467762 , 0.8467762 , 0.84733665],\n",
       "          [0.7586816 , 0.7586816 , 0.7653175 ],\n",
       "          [0.7801225 , 0.7801225 , 0.78796566]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.6884376 , 0.6860035 , 0.67816037],\n",
       "          [0.714629  , 0.714629  , 0.70678586],\n",
       "          [0.69944024, 0.69944024, 0.6915971 ],\n",
       "          ...,\n",
       "          [0.7624656 , 0.7624656 , 0.7624656 ],\n",
       "          [0.77838343, 0.77838343, 0.77838343],\n",
       "          [0.7929153 , 0.7929153 , 0.7929153 ]],\n",
       " \n",
       "         [[0.7174173 , 0.7174173 , 0.70957416],\n",
       "          [0.7022286 , 0.7022286 , 0.69438547],\n",
       "          [0.6628412 , 0.6628412 , 0.65499806],\n",
       "          ...,\n",
       "          [0.78069204, 0.78069204, 0.78069204],\n",
       "          [0.76581156, 0.76581156, 0.76581156],\n",
       "          [0.7739221 , 0.7739221 , 0.7739221 ]],\n",
       " \n",
       "         [[0.705017  , 0.705017  , 0.69717383],\n",
       "          [0.67176384, 0.67176384, 0.6639207 ],\n",
       "          [0.6451532 , 0.6451532 , 0.6373101 ],\n",
       "          ...,\n",
       "          [0.808655  , 0.808655  , 0.808655  ],\n",
       "          [0.784038  , 0.784038  , 0.784038  ],\n",
       "          [0.7691575 , 0.7691575 , 0.7691575 ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.41341642, 0.41341642, 0.41341642],\n",
       "          [0.4231586 , 0.4231586 , 0.4231586 ],\n",
       "          [0.41080087, 0.41080087, 0.41080087],\n",
       "          ...,\n",
       "          [0.81826943, 0.81826943, 0.81826943],\n",
       "          [0.7815606 , 0.7815606 , 0.7815606 ],\n",
       "          [0.8127017 , 0.8127017 , 0.8127017 ]],\n",
       " \n",
       "         [[0.33227968, 0.33227968, 0.33227968],\n",
       "          [0.38020015, 0.38020015, 0.38020015],\n",
       "          [0.4308239 , 0.4308239 , 0.4308239 ],\n",
       "          ...,\n",
       "          [0.79561365, 0.79561365, 0.79561365],\n",
       "          [0.7999262 , 0.7999262 , 0.7999262 ],\n",
       "          [0.82645285, 0.82645285, 0.82645285]],\n",
       " \n",
       "         [[0.42238316, 0.42238316, 0.42238316],\n",
       "          [0.3667735 , 0.3667735 , 0.3667735 ],\n",
       "          [0.3469839 , 0.3469839 , 0.3469839 ],\n",
       "          ...,\n",
       "          [0.7871507 , 0.7871507 , 0.7871507 ],\n",
       "          [0.82006514, 0.82006514, 0.82006514],\n",
       "          [0.8367509 , 0.8367509 , 0.8367509 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.73718876, 0.6822868 , 0.67836523],\n",
       "          [0.65709674, 0.6021948 , 0.5982732 ],\n",
       "          [0.6646391 , 0.6194743 , 0.6058156 ],\n",
       "          ...,\n",
       "          [0.73779726, 0.69466   , 0.6868169 ],\n",
       "          [0.7356415 , 0.6925042 , 0.6846611 ],\n",
       "          [0.727403  , 0.68426573, 0.6764226 ]],\n",
       " \n",
       "         [[0.6877579 , 0.6328559 , 0.6289343 ],\n",
       "          [0.6608065 , 0.6118091 , 0.60198295],\n",
       "          [0.6874232 , 0.64013463, 0.62583214],\n",
       "          ...,\n",
       "          [0.72083706, 0.6776998 , 0.66985667],\n",
       "          [0.7314095 , 0.68827224, 0.6804291 ],\n",
       "          [0.7407517 , 0.69761443, 0.6897713 ]],\n",
       " \n",
       "         [[0.65697384, 0.6041438 , 0.5981503 ],\n",
       "          [0.66826   , 0.6248041 , 0.609224  ],\n",
       "          [0.71831745, 0.66485006, 0.6526072 ],\n",
       "          ...,\n",
       "          [0.6941398 , 0.6510025 , 0.6431594 ],\n",
       "          [0.7106167 , 0.66747946, 0.6596363 ],\n",
       "          [0.7250218 , 0.6818845 , 0.6740414 ]]],\n",
       " \n",
       " \n",
       "        [[[0.70581084, 0.66911066, 0.6600098 ],\n",
       "          [0.7078306 , 0.67096883, 0.66194874],\n",
       "          [0.7098503 , 0.672827  , 0.6638877 ],\n",
       "          ...,\n",
       "          [0.79105407, 0.75575995, 0.73112774],\n",
       "          [0.78808457, 0.75279045, 0.7331826 ],\n",
       "          [0.7869776 , 0.75701106, 0.7347394 ]],\n",
       " \n",
       "         [[0.6115632 , 0.58270454, 0.57471067],\n",
       "          [0.61334056, 0.58432037, 0.5760841 ],\n",
       "          [0.615118  , 0.5859361 , 0.5774575 ],\n",
       "          ...,\n",
       "          [0.7913772 , 0.7560831 , 0.73177403],\n",
       "          [0.7878422 , 0.7525481 , 0.73294026],\n",
       "          [0.78705835, 0.7572534 , 0.734901  ]],\n",
       " \n",
       "         [[0.5604778 , 0.54197276, 0.5432289 ],\n",
       "          [0.559993  , 0.5411649 , 0.54234016],\n",
       "          [0.55950826, 0.54035693, 0.5414515 ],\n",
       "          ...,\n",
       "          [0.7917004 , 0.7564063 , 0.7324204 ],\n",
       "          [0.7875998 , 0.7523057 , 0.73269784],\n",
       "          [0.7871392 , 0.7574958 , 0.7350626 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.30807474, 0.2867377 , 0.29348463],\n",
       "          [0.3093441 , 0.29584852, 0.2997701 ],\n",
       "          [0.29913375, 0.29347965, 0.29849574],\n",
       "          ...,\n",
       "          [0.5668014 , 0.5079779 , 0.49621323],\n",
       "          [0.56550884, 0.5066853 , 0.49492058],\n",
       "          [0.5642162 , 0.5053927 , 0.49362794]],\n",
       " \n",
       "         [[0.30823633, 0.28706086, 0.293727  ],\n",
       "          [0.30902097, 0.29568696, 0.29960853],\n",
       "          [0.29921454, 0.293722  , 0.2988189 ],\n",
       "          ...,\n",
       "          [0.561704  , 0.50288045, 0.4911158 ],\n",
       "          [0.56235033, 0.5035268 , 0.4917621 ],\n",
       "          [0.5629966 , 0.5041731 , 0.49240842]],\n",
       " \n",
       "         [[0.3083979 , 0.28738403, 0.2939694 ],\n",
       "          [0.3086978 , 0.29552537, 0.29944694],\n",
       "          [0.29929534, 0.2939644 , 0.29914206],\n",
       "          ...,\n",
       "          [0.4399258 , 0.38110226, 0.36933756],\n",
       "          [0.44315737, 0.38433385, 0.37256914],\n",
       "          [0.44638902, 0.3875655 , 0.3758008 ]]],\n",
       " \n",
       " \n",
       "        [[[0.9407524 , 0.9368308 , 0.9616706 ],\n",
       "          [0.93787587, 0.9406618 , 0.97371125],\n",
       "          [0.92449784, 0.93465275, 0.96994686],\n",
       "          ...,\n",
       "          [0.69866794, 0.71043265, 0.7692562 ],\n",
       "          [0.6907225 , 0.70248723, 0.76131076],\n",
       "          [0.6827771 , 0.6945418 , 0.75336534]],\n",
       " \n",
       "         [[0.93280697, 0.9288854 , 0.95155823],\n",
       "          [0.9494328 , 0.9493295 , 0.9816567 ],\n",
       "          [0.9143855 , 0.92526275, 0.96055686],\n",
       "          ...,\n",
       "          [0.6609139 , 0.6726786 , 0.7315021 ],\n",
       "          [0.66741467, 0.6791794 , 0.7380029 ],\n",
       "          [0.67391545, 0.68568015, 0.74450374]],\n",
       " \n",
       "         [[0.9248616 , 0.92094004, 0.941446  ],\n",
       "          [0.9609897 , 0.9579972 , 0.9896021 ],\n",
       "          [0.90427315, 0.91587275, 0.95116687],\n",
       "          ...,\n",
       "          [0.69543904, 0.70720375, 0.7660273 ],\n",
       "          [0.70121753, 0.71298224, 0.77180576],\n",
       "          [0.70699596, 0.71876067, 0.77758425]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9190511 , 0.90889615, 0.8671629 ],\n",
       "          [0.9219403 , 0.9110631 , 0.8722191 ],\n",
       "          [0.9248296 , 0.91323   , 0.8772752 ],\n",
       "          ...,\n",
       "          [0.93655187, 0.9403082 , 0.88573664],\n",
       "          [0.9116621 , 0.9118943 , 0.8717496 ],\n",
       "          [0.88444847, 0.8880707 , 0.8343662 ]],\n",
       " \n",
       "         [[0.9412031 , 0.93168306, 0.88741016],\n",
       "          [0.94625926, 0.9374615 , 0.89029944],\n",
       "          [0.9513154 , 0.94324   , 0.89318866],\n",
       "          ...,\n",
       "          [0.9163272 , 0.9193613 , 0.86623424],\n",
       "          [0.91744053, 0.9183951 , 0.87536114],\n",
       "          [0.8895046 , 0.89240456, 0.8415892 ]],\n",
       " \n",
       "         [[0.9289877 , 0.9298549 , 0.87669694],\n",
       "          [0.92104226, 0.9247988 , 0.87091845],\n",
       "          [0.9130969 , 0.9197426 , 0.86514   ],\n",
       "          ...,\n",
       "          [0.89610255, 0.8984143 , 0.8467319 ],\n",
       "          [0.923219  , 0.9248959 , 0.87897265],\n",
       "          [0.8945608 , 0.8967384 , 0.84881234]]]], dtype=float32),\n",
       " array([2, 2, 2, 4, 4, 4, 2, 5, 5, 2, 2, 2, 4, 5, 5, 4, 2, 4, 4, 5, 5, 5,\n",
       "        4, 6, 2, 2, 2, 1, 5, 3, 3, 3], dtype=int64))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 224, 224, 3), dtype=float32, numpy=\n",
       "array([[[[0.1296265 , 0.14531277, 0.15465821],\n",
       "         [0.07340999, 0.08909626, 0.0945647 ],\n",
       "         [0.03816466, 0.05385094, 0.05777251],\n",
       "         ...,\n",
       "         [0.34910387, 0.39502418, 0.42808345],\n",
       "         [0.28760058, 0.33858097, 0.3699535 ],\n",
       "         [0.2634084 , 0.31438878, 0.34576133]],\n",
       "\n",
       "        [[0.0789327 , 0.09461897, 0.10638368],\n",
       "         [0.15453422, 0.1702205 , 0.1819852 ],\n",
       "         [0.11605293, 0.1317392 , 0.14014854],\n",
       "         ...,\n",
       "         [0.3199504 , 0.3709308 , 0.40230337],\n",
       "         [0.24495356, 0.29593396, 0.3273065 ],\n",
       "         [0.3021784 , 0.3531588 , 0.38453135]],\n",
       "\n",
       "        [[0.02863161, 0.04431789, 0.0560826 ],\n",
       "         [0.0215853 , 0.03727157, 0.04903628],\n",
       "         [0.09718683, 0.1128731 , 0.1246378 ],\n",
       "         ...,\n",
       "         [0.27730337, 0.32828376, 0.35965633],\n",
       "         [0.27276948, 0.32374987, 0.35512242],\n",
       "         [0.28269508, 0.33367547, 0.36504802]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4409756 , 0.44256708, 0.45126295],\n",
       "         [0.43873304, 0.44041073, 0.4471215 ],\n",
       "         [0.5083218 , 0.48927802, 0.49620304],\n",
       "         ...,\n",
       "         [0.38381544, 0.37113264, 0.3576367 ],\n",
       "         [0.32178342, 0.3168546 , 0.30142015],\n",
       "         [0.34577262, 0.34185106, 0.32616478]],\n",
       "\n",
       "        [[0.40050146, 0.4036496 , 0.41624215],\n",
       "         [0.48626515, 0.48339623, 0.48443946],\n",
       "         [0.53739935, 0.49703202, 0.51171106],\n",
       "         ...,\n",
       "         [0.4257942 , 0.4011533 , 0.39106628],\n",
       "         [0.43086973, 0.41230512, 0.4002796 ],\n",
       "         [0.3688377 , 0.3580271 , 0.3440631 ]],\n",
       "\n",
       "        [[0.4509025 , 0.4521121 , 0.45695063],\n",
       "         [0.51534265, 0.49115023, 0.49994746],\n",
       "         [0.5344297 , 0.5064727 , 0.5170989 ],\n",
       "         ...,\n",
       "         [0.38803706, 0.3671501 , 0.35581174],\n",
       "         [0.41403064, 0.38497838, 0.37636182],\n",
       "         [0.42953864, 0.40630192, 0.39574683]]],\n",
       "\n",
       "\n",
       "       [[[0.30357996, 0.31053397, 0.39895177],\n",
       "         [0.30483794, 0.31197163, 0.40074888],\n",
       "         [0.3060959 , 0.31340933, 0.40254596],\n",
       "         ...,\n",
       "         [0.63841975, 0.5831198 , 0.5957655 ],\n",
       "         [0.53420293, 0.47537944, 0.48714414],\n",
       "         [0.587758  , 0.5289345 , 0.52250457]],\n",
       "\n",
       "        [[0.2646526 , 0.26857418, 0.3509271 ],\n",
       "         [0.2682468 , 0.27216837, 0.35452133],\n",
       "         [0.271841  , 0.27576256, 0.35811552],\n",
       "         ...,\n",
       "         [0.6369821 , 0.5809633 , 0.5934292 ],\n",
       "         [0.5284522 , 0.46962872, 0.48139343],\n",
       "         [0.5926102 , 0.53378665, 0.52627856]],\n",
       "\n",
       "        [[0.21096876, 0.21489033, 0.2972433 ],\n",
       "         [0.20953108, 0.21345265, 0.2958056 ],\n",
       "         [0.2080934 , 0.21201497, 0.29436794],\n",
       "         ...,\n",
       "         [0.6355444 , 0.57880676, 0.59109294],\n",
       "         [0.5227015 , 0.463878  , 0.4756427 ],\n",
       "         [0.59746236, 0.53863883, 0.5300524 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6178052 , 0.5748815 , 0.5246444 ],\n",
       "         [0.63242376, 0.57311547, 0.504104  ],\n",
       "         [0.6605963 , 0.6457027 , 0.5900081 ],\n",
       "         ...,\n",
       "         [0.9147685 , 0.8619525 , 0.8114935 ],\n",
       "         [0.91512793, 0.8630307 , 0.8127515 ],\n",
       "         [0.91548735, 0.864109  , 0.8140095 ]],\n",
       "\n",
       "        [[0.618524  , 0.57434237, 0.52302694],\n",
       "         [0.63278323, 0.57599086, 0.50751853],\n",
       "         [0.6679644 , 0.6519926 , 0.59737617],\n",
       "         ...,\n",
       "         [0.8797658 , 0.82146794, 0.79086334],\n",
       "         [0.88156295, 0.8234447 , 0.7917619 ],\n",
       "         [0.88336   , 0.8254215 , 0.7926605 ]],\n",
       "\n",
       "        [[0.61924285, 0.5738032 , 0.5214096 ],\n",
       "         [0.6331426 , 0.5788662 , 0.51093304],\n",
       "         [0.67533255, 0.65828246, 0.6047443 ],\n",
       "         ...,\n",
       "         [0.5047982 , 0.44597465, 0.42530736],\n",
       "         [0.5243865 , 0.46556297, 0.44453627],\n",
       "         [0.5439748 , 0.48515132, 0.4637652 ]]],\n",
       "\n",
       "\n",
       "       [[[0.2869842 , 0.2992812 , 0.35757244],\n",
       "         [0.30126834, 0.3242784 , 0.3718566 ],\n",
       "         [0.3223483 , 0.35267353, 0.4031303 ],\n",
       "         ...,\n",
       "         [0.36838394, 0.20147192, 0.17794251],\n",
       "         [0.3456951 , 0.18202436, 0.15849495],\n",
       "         [0.32868385, 0.16789953, 0.14437011]],\n",
       "\n",
       "        [[0.26462644, 0.27639115, 0.33521467],\n",
       "         [0.29478583, 0.312934  , 0.36537406],\n",
       "         [0.3126245 , 0.3397085 , 0.38854462],\n",
       "         ...,\n",
       "         [0.3346197 , 0.1738354 , 0.15030597],\n",
       "         [0.36379108, 0.20300673, 0.17947732],\n",
       "         [0.3929624 , 0.23217808, 0.20864867]],\n",
       "\n",
       "        [[0.24031699, 0.25208166, 0.31090522],\n",
       "         [0.28830332, 0.3015896 , 0.35889155],\n",
       "         [0.30290073, 0.32674348, 0.37395895],\n",
       "         ...,\n",
       "         [0.39419857, 0.23372757, 0.21004151],\n",
       "         [0.374751  , 0.21752127, 0.19221458],\n",
       "         [0.35530347, 0.20131496, 0.17438763]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.13178568, 0.18694365, 0.07636006],\n",
       "         [0.1755427 , 0.21935625, 0.11849645],\n",
       "         [0.21929972, 0.25176886, 0.16063283],\n",
       "         ...,\n",
       "         [0.5656459 , 0.53035176, 0.4950576 ],\n",
       "         [0.5442197 , 0.5089255 , 0.47363144],\n",
       "         [0.5840702 , 0.5487761 , 0.513482  ]],\n",
       "\n",
       "        [[0.22266385, 0.25334397, 0.16453278],\n",
       "         [0.2145607 , 0.23875828, 0.16291215],\n",
       "         [0.20645754, 0.22417259, 0.16129151],\n",
       "         ...,\n",
       "         [0.57536966, 0.54007554, 0.5047814 ],\n",
       "         [0.55394346, 0.51864934, 0.4833552 ],\n",
       "         [0.5613814 , 0.5260873 , 0.49079314]],\n",
       "\n",
       "        [[0.2048087 , 0.22120467, 0.16096175],\n",
       "         [0.17938708, 0.19218694, 0.13624983],\n",
       "         [0.15183637, 0.16139495, 0.1086991 ],\n",
       "         ...,\n",
       "         [0.5850934 , 0.54979926, 0.51450515],\n",
       "         [0.56366724, 0.5283731 , 0.493079  ],\n",
       "         [0.54224104, 0.5069469 , 0.4716528 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.6284886 , 0.6552639 , 0.59387016],\n",
       "         [0.98037183, 0.98037183, 0.97240615],\n",
       "         [0.9765264 , 0.9765264 , 0.9454879 ],\n",
       "         ...,\n",
       "         [0.18786344, 0.19178501, 0.1682556 ],\n",
       "         [0.15249585, 0.15641743, 0.132888  ],\n",
       "         [0.12292004, 0.12684162, 0.1033122 ]],\n",
       "\n",
       "        [[0.63372684, 0.65848845, 0.60044974],\n",
       "         [0.9115357 , 0.9167748 , 0.8984535 ],\n",
       "         [0.9772952 , 0.9772952 , 0.9508699 ],\n",
       "         ...,\n",
       "         [0.15522839, 0.15914996, 0.13562055],\n",
       "         [0.16599244, 0.169914  , 0.14638458],\n",
       "         [0.17618471, 0.18010628, 0.15657687]],\n",
       "\n",
       "        [[0.6498729 , 0.6715591 , 0.6189023 ],\n",
       "         [0.8408005 , 0.85142165, 0.82233626],\n",
       "         [0.97806406, 0.97806406, 0.956252  ],\n",
       "         ...,\n",
       "         [0.14387639, 0.14779796, 0.12426854],\n",
       "         [0.13311234, 0.13703391, 0.11350449],\n",
       "         [0.12234829, 0.12626985, 0.10274044]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5035991 , 0.47614813, 0.4016383 ],\n",
       "         [0.47207582, 0.44462484, 0.370115  ],\n",
       "         [0.44055253, 0.41310155, 0.33859175],\n",
       "         ...,\n",
       "         [0.10416503, 0.11127342, 0.08615059],\n",
       "         [0.08109228, 0.09285699, 0.065406  ],\n",
       "         [0.07531382, 0.08707853, 0.05962754]],\n",
       "\n",
       "        [[0.34593529, 0.3184843 , 0.24397448],\n",
       "         [0.37054503, 0.34309405, 0.26858422],\n",
       "         [0.3966863 , 0.3692353 , 0.2947255 ],\n",
       "         ...,\n",
       "         [0.10877819, 0.11434887, 0.0899949 ],\n",
       "         [0.08570544, 0.09747014, 0.07001916],\n",
       "         [0.07070065, 0.08246536, 0.05501438]],\n",
       "\n",
       "        [[0.4751494 , 0.4476984 , 0.37318859],\n",
       "         [0.4824654 , 0.4550144 , 0.38050458],\n",
       "         [0.48707855, 0.45962757, 0.38511777],\n",
       "         ...,\n",
       "         [0.11339136, 0.11742431, 0.09383921],\n",
       "         [0.09031861, 0.10204247, 0.07461191],\n",
       "         [0.06724585, 0.07901055, 0.05155957]]],\n",
       "\n",
       "\n",
       "       [[[0.26431024, 0.32313377, 0.45254555],\n",
       "         [0.2475045 , 0.30632806, 0.43573982],\n",
       "         [0.28110087, 0.3399244 , 0.46933618],\n",
       "         ...,\n",
       "         [0.16443473, 0.14090532, 0.14250106],\n",
       "         [0.15112244, 0.12759303, 0.13052002],\n",
       "         [0.13781016, 0.11428074, 0.11853894]],\n",
       "\n",
       "        [[0.27362886, 0.3324524 , 0.46186414],\n",
       "         [0.24484204, 0.30366558, 0.43307734],\n",
       "         [0.27244788, 0.3312714 , 0.4606832 ],\n",
       "         ...,\n",
       "         [0.11455729, 0.08880497, 0.09590714],\n",
       "         [0.12587273, 0.09812357, 0.10456012],\n",
       "         [0.1371882 , 0.10744218, 0.11321311]],\n",
       "\n",
       "        [[0.28294745, 0.34177098, 0.47118276],\n",
       "         [0.24217959, 0.30100313, 0.4304149 ],\n",
       "         [0.2637949 , 0.32261842, 0.45203018],\n",
       "         ...,\n",
       "         [0.1788885 , 0.14359438, 0.1420434 ],\n",
       "         [0.18887274, 0.15357861, 0.1467027 ],\n",
       "         [0.19885695, 0.16356283, 0.151362  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.23001145, 0.20849733, 0.24166712],\n",
       "         [0.22268969, 0.20050995, 0.23567659],\n",
       "         [0.21536791, 0.19252257, 0.22968605],\n",
       "         ...,\n",
       "         [0.18723287, 0.17478408, 0.15654439],\n",
       "         [0.1485862 , 0.13046028, 0.10767184],\n",
       "         [0.21614522, 0.19028997, 0.16051316]],\n",
       "\n",
       "        [[0.17455451, 0.15842257, 0.19948763],\n",
       "         [0.16257344, 0.14910397, 0.19083464],\n",
       "         [0.15059237, 0.13978535, 0.18218166],\n",
       "         ...,\n",
       "         [0.19388902, 0.18077463, 0.16386615],\n",
       "         [0.15524232, 0.13844766, 0.11632483],\n",
       "         [0.20017046, 0.17564645, 0.14720087]],\n",
       "\n",
       "        [[0.15338711, 0.14554398, 0.18868123],\n",
       "         [0.15937766, 0.15153451, 0.19467178],\n",
       "         [0.16536818, 0.15752505, 0.2006623 ],\n",
       "         ...,\n",
       "         [0.20054516, 0.18676515, 0.17118792],\n",
       "         [0.16189848, 0.14643504, 0.12497782],\n",
       "         [0.18419571, 0.16100293, 0.13388859]]],\n",
       "\n",
       "\n",
       "       [[[0.6209531 , 0.6752474 , 0.7169666 ],\n",
       "         [0.6108083 , 0.66547793, 0.7097767 ],\n",
       "         [0.60167634, 0.65591115, 0.7023841 ],\n",
       "         ...,\n",
       "         [0.97162384, 0.97162384, 0.97162384],\n",
       "         [0.97629225, 0.97629225, 0.97629225],\n",
       "         [0.96159464, 0.96159464, 0.96159464]],\n",
       "\n",
       "        [[0.7147929 , 0.7575734 , 0.7741517 ],\n",
       "         [0.7109788 , 0.75488555, 0.7723671 ],\n",
       "         [0.6996726 , 0.74488384, 0.7654094 ],\n",
       "         ...,\n",
       "         [0.9728297 , 0.9728297 , 0.9728297 ],\n",
       "         [0.9754448 , 0.9754448 , 0.9754448 ],\n",
       "         [0.9614813 , 0.9614813 , 0.9614813 ]],\n",
       "\n",
       "        [[0.6558272 , 0.69127554, 0.72656965],\n",
       "         [0.65939254, 0.6952479 , 0.7291388 ],\n",
       "         [0.6663502 , 0.7030753 , 0.7347919 ],\n",
       "         ...,\n",
       "         [0.9732646 , 0.9732646 , 0.9732646 ],\n",
       "         [0.97370535, 0.97370535, 0.97370535],\n",
       "         [0.9627858 , 0.9627858 , 0.9627858 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.64414644, 0.6245386 , 0.6088523 ],\n",
       "         [0.6362119 , 0.61660403, 0.60091776],\n",
       "         [0.6153423 , 0.5957345 , 0.5800482 ],\n",
       "         ...,\n",
       "         [0.41184717, 0.4464258 , 0.4646026 ],\n",
       "         [0.39749697, 0.43251044, 0.45155695],\n",
       "         [0.38977733, 0.42430043, 0.44359988]],\n",
       "\n",
       "        [[0.6537132 , 0.6341054 , 0.6184191 ],\n",
       "         [0.63316786, 0.61356   , 0.59787375],\n",
       "         [0.613168  , 0.59356016, 0.5778739 ],\n",
       "         ...,\n",
       "         [0.5535961 , 0.5822033 , 0.5925853 ],\n",
       "         [0.53098357, 0.56133026, 0.572582  ],\n",
       "         [0.5117604 , 0.54331136, 0.5554328 ]],\n",
       "\n",
       "        [[0.65740556, 0.6377977 , 0.62211144],\n",
       "         [0.63048065, 0.6108728 , 0.59518653],\n",
       "         [0.6133067 , 0.59369886, 0.5780126 ],\n",
       "         ...,\n",
       "         [0.7422501 , 0.75793636, 0.7618579 ],\n",
       "         [0.72876954, 0.7444558 , 0.7483774 ],\n",
       "         [0.7110351 , 0.7275316 , 0.7318584 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 4., 4., 5., 4., 4., 6., 5., 2., 2., 5., 2., 2., 2., 4., 6., 4.,\n",
       "       5., 6., 2., 5., 4., 2., 6., 2., 2., 5., 4., 3., 2., 2., 2.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have your original training data in 'train_data'\n",
    "# train_data, val_data = train_test_split(train, test_size=0.2, random_state=42)\n",
    "# Build a CNN model(same as tiny VGG )\n",
    "\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=10,\n",
    "                           kernel_size = 3,\n",
    "                           activation=\"relu\",\n",
    "                           input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2,\n",
    "                              padding=\"valid\"),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_1.compile(loss= \"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.preprocessing.image.DataFrameIterator"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the EfficientNetV2 base model\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create input layers for images and labels\n",
    "image_input = tf.keras.layers.Input(shape=(224, 224, 3), name=\"image_input\")\n",
    "label_input = tf.keras.layers.Input(shape=(1,), name=\"label_input\")\n",
    "\n",
    "# Pass images through the base model\n",
    "x = base_model(image_input)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "\n",
    "# Concatenate the flattened image tensor with the label input\n",
    "concatenated = tf.keras.layers.concatenate([x, label_input])\n",
    "\n",
    "# Create the output layer\n",
    "outputs = tf.keras.layers.Dense(6, activation=\"softmax\", name=\"output_layer\")(concatenated)\n",
    "\n",
    "# Combine the inputs with the outputs into a model\n",
    "model_0 = tf.keras.Model(inputs=[image_input, label_input], outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_0.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after passing inputs through base model: (None, 7, 7, 1280)\n",
      "Shape after GlobalAveragePooling2D: (None, 1280)\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a base model tf.keras.application\n",
    "\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
    "\n",
    "# 2. freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Create inputs into our model\n",
    "inputs = tf.keras.layers.Input(shape=(224,224,3), name=\"input_layer\")\n",
    "\n",
    "# 4. for resnet\n",
    "\n",
    "# 5. Pass the inputs to the base model\n",
    "x = base_model(inputs)\n",
    "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
    "\n",
    "# 6. Avarage pool outputs of the model (aggregation all the most important information, reduce number of computations)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name = \"Gloabal_average_pooling_layer\")(x)\n",
    "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(6, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# 8. combine the inputes with the outputs into a model\n",
    "model_0 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "#9. Compile the model\n",
    "model_0.compile(loss= \"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# # 10. fit the model\n",
    "\n",
    "# history_model_0 = model_0.fit(train_data,\n",
    "#                                  epochs = 5,\n",
    "#                                  steps_per_epoch=len(train_data),\n",
    "#                                  validation_data=val_data,\n",
    "#                                  validation_steps=val_data\n",
    "#                                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss= \"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1128, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"c:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1082, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=sparse_categorical_crossentropy, and therefore expects target data to be provided in `fit()`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Hackthon\\exp_1.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 10. fit the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history_model_0 \u001b[39m=\u001b[39m model_0\u001b[39m.\u001b[39;49mfit(batch,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                  epochs \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                  steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(batch),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                  validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                  validation_steps\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39m0.25\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39mlen\u001b[39;49m(batch))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                  )\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\TEMP\\__autograph_generated_file7n5n8oyz.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1128, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"c:\\Users\\ADMIN\\anaconda3\\envs\\tf\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1082, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=sparse_categorical_crossentropy, and therefore expects target data to be provided in `fit()`.\n"
     ]
    }
   ],
   "source": [
    "# 10. fit the model\n",
    "\n",
    "history_model_0 = model_0.fit(batch,\n",
    "                                 epochs = 5,\n",
    "                                 steps_per_epoch=len(batch),\n",
    "                                 validation_split=0.2,\n",
    "                                 validation_steps=int(0.25 * len(batch))\n",
    "                                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      image_id  filename  label\n",
      "0            1     1.jpg      2\n",
      "1            2     2.jpg      4\n",
      "2            3     3.jpg      2\n",
      "3            4     4.jpg      3\n",
      "4            5     5.jpg      5\n",
      "...        ...       ...    ...\n",
      "7195      7196  7196.jpg      4\n",
      "7196      7197  7197.jpg      4\n",
      "7197      7198  7198.jpg      4\n",
      "7198      7199  7199.jpg      2\n",
      "7199      7200  7200.jpg      2\n",
      "\n",
      "[7200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd. read_csv(\"train/train/train.csv\")\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'train/train/images'\n",
    "image_names = df['filename']\n",
    "labels = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    image_names, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034    5\n",
      "3250    5\n",
      "3366    4\n",
      "1423    2\n",
      "122     4\n",
      "       ..\n",
      "3772    4\n",
      "5191    4\n",
      "5226    4\n",
      "5390    2\n",
      "860     4\n",
      "Name: label, Length: 5760, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224,224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    \n",
    ")\n",
    "# Define your data generator\n",
    " \n",
    "test_gen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_gen.flow_from_dataframe(directory=train_dir,\n",
    "                                                                            image_size=IMG_SIZE,\n",
    "                                                                            label_mode=\"categorical\",\n",
    "                                                                            batch_size=BATCH_SIZE)\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory= test_dir,\n",
    "                                                                image_size= IMG_SIZE,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_gen.flow_from_dataframe(dataframe = train, \n",
    "                                           directory = train_folder, x_col = name of your column with image, \n",
    "y_col = name of column of your labels, seed = 42,\n",
    "batch_size = size of your batch, shuffle = True, \n",
    "class_mode=\"categorical\",target_size = (height of image, width of image))\n",
    "\n",
    "test_data = test_gen.flow_from_dataframe(dataframe = test, \n",
    "directory = test_folder, x_col = name of your column with image, \n",
    "y_col = None,\n",
    "batch_size = size of your batch, shuffle = False, \n",
    "class_mode=None,target_size = (height of image, width of image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_image(img_path, label):\n",
    "#     img = load_and_preprocess_image(img_path)  # Custom function to load and preprocess image\n",
    "#     label = one_hot_encode(label)  # Custom function for one-hot encoding\n",
    "#     return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_and_preprocess_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Hackthon\\exp_1.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Apply preprocessing to training and validation data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_data \u001b[39m=\u001b[39m [(preprocess_image(image_folder \u001b[39m+\u001b[39;49m img, label)) \u001b[39mfor\u001b[39;49;00m img, label \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(train_images, train_labels)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m val_data \u001b[39m=\u001b[39m [(preprocess_image(image_folder \u001b[39m+\u001b[39m img, label)) \u001b[39mfor\u001b[39;00m img, label \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(val_images, val_labels)]\n",
      "\u001b[1;32md:\\Hackthon\\exp_1.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Apply preprocessing to training and validation data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_data \u001b[39m=\u001b[39m [(preprocess_image(image_folder \u001b[39m+\u001b[39;49m img, label)) \u001b[39mfor\u001b[39;00m img, label \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(train_images, train_labels)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m val_data \u001b[39m=\u001b[39m [(preprocess_image(image_folder \u001b[39m+\u001b[39m img, label)) \u001b[39mfor\u001b[39;00m img, label \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(val_images, val_labels)]\n",
      "\u001b[1;32md:\\Hackthon\\exp_1.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_image\u001b[39m(img_path, label):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     img \u001b[39m=\u001b[39m load_and_preprocess_image(img_path)  \u001b[39m# Custom function to load and preprocess image\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     label \u001b[39m=\u001b[39m one_hot_encode(label)  \u001b[39m# Custom function for one-hot encoding\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hackthon/exp_1.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img, label\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_and_preprocess_image' is not defined"
     ]
    }
   ],
   "source": [
    "# # Apply preprocessing to training and validation data\n",
    "# train_data = [(preprocess_image(image_folder + img, label)) for img, label in zip(train_images, train_labels)]\n",
    "# val_data = [(preprocess_image(image_folder + img, label)) for img, label in zip(val_images, val_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
